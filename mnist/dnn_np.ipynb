{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(object):\n",
    "    \"\"\"\n",
    "    全连接层\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_units, output_units):\n",
    "        self._input_units = input_units\n",
    "        self._output_units = output_units\n",
    "        self.weight = np.random.standard_normal(size=(input_units, output_units))\n",
    "        self.biase = np.zeros((input_units,))  # TODO use none-zero value\n",
    "\n",
    "    def feed_forward(self, inputs, use_activation_fuc=True):\n",
    "        self.input = inputs\n",
    "        self.out = np.matmul(inputs, self.weight)\n",
    "        if use_activation_fuc:\n",
    "            self.out = self.activation_fuc(self.out)\n",
    "        return self.out\n",
    "\n",
    "    def activation_fuc(self, x):\n",
    "        \"\"\"\n",
    "        use sigmod\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def d_out_wrt_net(self):\n",
    "        # ∂oᵢ/∂netᵢ\n",
    "        return self.out * (1 - self.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(batch_size=36):\n",
    "    x = np.random.random_sample((batch_size, 1))\n",
    "    # y = 3.5 * x + 2\n",
    "    y = np.where(x > 0.5, 1, 0)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def compute_loss(predictions, labels):\n",
    "    \"\"\"\n",
    "    使用l2 loss\n",
    "    \"\"\"\n",
    "    return np.sum(np.power(labels - predictions, 2) / 2)\n",
    "\n",
    "\n",
    "def compute_accuracy(preditions, labels):\n",
    "    return np.abs(np.sum(np.equal(np.where(preditions > 0.5, 1, 0), labels)) / len(preditions) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "o_i = \\gamma(net_i) \\\\\\\\\n",
    "E = \\sum[t\\cdot\\log(y) + (1-t)\\cdot\\log(1-y)]\n",
    "$$\n",
    "\n",
    "其中:\n",
    " - $\\gamma$ 是激活函数\n",
    " - **E** 是误差(这里使用Cross Entropy Loss), **y**是为输出神经元的实际输出， **t**为样本的预期输出\n",
    "\n",
    "所以求误差对于权重的偏微分:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\dfrac{\\sigma(E)}{\\sigma(\\omega_{i, j})} &= \\dfrac{\\sigma(E)}{\\sigma(o_j)} \\cdot \\dfrac{\\sigma(o_j)}{\\sigma(net_j)} \\cdot \\dfrac{\\sigma(net_j)}{\\sigma(\\omega_{i, j})} \\\\\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params=1, maxstep=1000, batch_size=32):\n",
    "    print('开始训练')\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    fc2_weight_list = []\n",
    "    fc1_weight_list = []\n",
    "\n",
    "    # 建立模型\n",
    "    fc1 = FCLayer(params, 5)\n",
    "    fc2 = FCLayer(5, 1)\n",
    "\n",
    "    def predict(input):\n",
    "        return fc2.feed_forward(fc1.feed_forward(input))\n",
    "\n",
    "    step = 0\n",
    "    while step < maxstep:\n",
    "        # 生成训练数据\n",
    "        inputs, labels = generate_data(batch_size)\n",
    "        # forward propagation\n",
    "        fc1_output = fc1.feed_forward(inputs)\n",
    "        fc2_output = fc2.feed_forward(fc1_output)\n",
    "        # 误差\n",
    "        loss = compute_loss(fc2_output, labels)\n",
    "\n",
    "        # 最后一层的delta\n",
    "        delta_out = (fc2_output - labels) * fc2_output * (1 - fc2_output)  # [batch_size, out]\n",
    "        # 隐藏层的delta\n",
    "        # [batch_size, out] * [unit_1, out].T\n",
    "        delta_hidden = np.dot(delta_out, fc2.weight.T) * fc2_output * (1 - fc2_output)  # [batch_size, unit_1]\n",
    "\n",
    "        # 更新参数，weight\n",
    "        # [unit_1, out] = [batch_size, unit_1].T * [batch_size, out]\n",
    "        fc2.weight -= LR * np.dot(fc1.out.T, delta_out)\n",
    "        # [input, unit_1] = [batch_size, input].T * [batch_size, unit_1]\n",
    "        fc1.weight -= LR * np.dot(inputs.T, delta_hidden)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            accuracy = compute_accuracy(fc2_output, labels)\n",
    "            print('step: %d , loss: %0.4f, accuracy: %0.2f' % (step, loss, accuracy))\n",
    "            # print(fc2.weight)\n",
    "            loss_list.append(loss)\n",
    "            accuracy_list.append(accuracy)\n",
    "            fc2_weight_list.append(np.average(fc2.weight))\n",
    "            fc1_weight_list.append(np.average(fc1.weight))\n",
    "        step += 1\n",
    "\n",
    "    # test\n",
    "    test_data, test_label = generate_data(100)\n",
    "    results = predict(test_data)\n",
    "    print('正确率: %0.2f' % compute_accuracy(results, test_label))\n",
    "\n",
    "\n",
    "    # plot weight\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(top=0.8)\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax1.set_ylabel('percent')\n",
    "    ax1.set_title('accuracy')\n",
    "    ax1.plot(np.arange(len(accuracy_list)), accuracy_list, color='blue', lw=2)\n",
    "\n",
    "    ax2 = fig.add_axes([0.15, 0.1, 0.7, 0.3])\n",
    "    ax2.plot(np.arange(len(loss_list)), loss_list, color='yellow', lw=2)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "def train(params=1, maxstep=1000, batch_size=32):\n",
    "    print('开始训练')\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    fc2_weight_list = []\n",
    "    fc1_weight_list = []\n",
    "\n",
    "    # 建立模型\n",
    "    fc1 = FCLayer(params, 5)\n",
    "    fc2 = FCLayer(5, 1)\n",
    "\n",
    "    def predict(input):\n",
    "        return fc2.feed_forward(fc1.feed_forward(input))\n",
    "\n",
    "    step = 0\n",
    "    while step < maxstep:\n",
    "        # 生成训练数据\n",
    "        inputs, labels = generate_data(batch_size)\n",
    "        # forward propagation\n",
    "        fc1_output = fc1.feed_forward(inputs)\n",
    "        fc2_output = fc2.feed_forward(fc1_output)\n",
    "        # 误差\n",
    "        loss = compute_loss(fc2_output, labels)\n",
    "\n",
    "        # 最后一层的delta\n",
    "        delta_out = (fc2_output - labels) * fc2_output * (1 - fc2_output)  # [batch_size, out]\n",
    "        # 隐藏层的delta\n",
    "        # [batch_size, out] * [unit_1, out].T\n",
    "        delta_hidden = np.dot(delta_out, fc2.weight.T) * fc2_output * (1 - fc2_output)  # [batch_size, unit_1]\n",
    "\n",
    "        # 更新参数，weight\n",
    "        # [unit_1, out] = [batch_size, unit_1].T * [batch_size, out]\n",
    "        fc2.weight -= LR * np.dot(fc1.out.T, delta_out)\n",
    "        # [input, unit_1] = [batch_size, input].T * [batch_size, unit_1]\n",
    "        fc1.weight -= LR * np.dot(inputs.T, delta_hidden)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            accuracy = compute_accuracy(fc2_output, labels)\n",
    "            print('step: %d , loss: %0.4f, accuracy: %0.2f' % (step, loss, accuracy))\n",
    "            # print(fc2.weight)\n",
    "            loss_list.append(loss)\n",
    "            accuracy_list.append(accuracy)\n",
    "            fc2_weight_list.append(np.average(fc2.weight))\n",
    "            fc1_weight_list.append(np.average(fc1.weight))\n",
    "        step += 1\n",
    "\n",
    "    # test\n",
    "    test_data, test_label = generate_data(100)\n",
    "    results = predict(test_data)\n",
    "    print('正确率: %0.2f' % compute_accuracy(results, test_label))\n",
    "\n",
    "\n",
    "    # plot weight\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(top=0.8)\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    ax1.set_ylabel('percent')\n",
    "    ax1.set_title('accuracy')\n",
    "    ax1.plot(np.arange(len(accuracy_list)), accuracy_list, color='blue', lw=2)\n",
    "\n",
    "    ax2 = fig.add_axes([0.15, 0.1, 0.7, 0.3])\n",
    "    ax2.plot(np.arange(len(loss_list)), loss_list, color='yellow', lw=2)\n",
    "    plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "# step: 0 , loss: 1.4918, accuracy: 10.00\n",
    "# step: 100 , loss: 1.1960, accuracy: 70.00\n",
    "# step: 200 , loss: 0.9805, accuracy: 90.00\n",
    "# step: 300 , loss: 0.8510, accuracy: 70.00\n",
    "# step: 400 , loss: 0.4447, accuracy: 90.00\n",
    "# step: 500 , loss: 0.5089, accuracy: 90.00\n",
    "# step: 600 , loss: 0.2708, accuracy: 100.00\n",
    "# step: 700 , loss: 0.3503, accuracy: 100.00\n",
    "# step: 800 , loss: 0.5821, accuracy: 80.00\n",
    "# step: 900 , loss: 0.3951, accuracy: 90.00\n",
    "# 正确率: 95.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![trends](Figure_1.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
